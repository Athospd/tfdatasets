% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text_line_dataset.R
\name{delim_dataset}
\alias{delim_dataset}
\alias{csv_dataset}
\alias{tsv_dataset}
\title{Create a dataset from a text file with delimited values}
\usage{
delim_dataset(filenames, compression_type = NULL, delim, col_names = NULL,
  col_types = NULL, col_defaults = NULL, skip = 0,
  parallel_records = NULL)

csv_dataset(filenames, compression_type = NULL, col_names = NULL,
  col_types = NULL, col_defaults = NULL, skip = 0,
  parallel_records = NULL)

tsv_dataset(filenames, compression_type = NULL, col_names = NULL,
  col_types = NULL, col_defaults = NULL, skip = 0,
  parallel_records = NULL)
}
\arguments{
\item{filenames}{Characater vector containing one or more filenames or
filename glob patterns (e.g. "train.csv", "\emph{.csv", "}-train.csv", etc.)}

\item{compression_type}{A string, one of: \code{"auto"} (determine based on file
extension), \code{""} (no compression), \code{"ZLIB"}, or \code{"GZIP"}. For
\code{"auto"}, GZIP will be automatically selected if any of
the \code{filenames} have a .gz extension and ZLIB will be automatically
selected if any of the \code{filenames} have a .zlib extension (otherwise
no compression will be used).}

\item{delim}{Character delimiter to separate fields in a record (defaults to
",")}

\item{col_names}{Character vector with column names (or \code{NULL} to
automatically detect the column names from the first row of the input
file).

If \code{col_names} is a character vector, the values will be used as the names
of the columns, and the first row of the input will be read into the first
row of the datset. Note that if the underlying text file also includes
column names in it's first row, this row should be skipped explicitly with
\code{\link[=dataset_skip]{dataset_skip()}}.

If \code{NULL}, the first row of the input will be used as the column names, and
will not be included in dataset.}

\item{col_types}{Column types. If NULL, all column types will be imputed from
the first 1000 rows on the input. This is convenient (and fast), but not
robust. If the imputation fails, you'll need to supply the correct types
yourself.

Types can be explicitliy specified in a character vector as "integer",
"double", and "character" (e.g. \code{col_types = c("double", "double", "integer"}).

Alternatively, you can use a compact string representation where each
character represents one column: c = character, i = integer, d = double
(e.g. \code{col_types =}ddi`).}

\item{col_defaults}{List of default values which are used when data is
missing from a record (e.g. \code{list(0, 0, 0L}). If \code{NULL} then defaults will
be automatically provided based on \code{col_types} (\code{0} for numeric columns and
\code{""} for character columns).}

\item{skip}{Number of lines to skip before reading data. Note that if
\code{col_names} is explicitly provided and there are column names witin the CSV
file then \code{skip} should be set to 1 to ensure that the column names are
bypassed.}

\item{parallel_records}{(Optional) An integer, representing the number of
records to decode in parallel. If not specified, records will be
processed sequentially.}
}
\description{
Create a dataset from a text file with delimited values
}
\note{
The \code{\link[=delim_dataset]{delim_dataset()}} function is a convenience wrapper for the
\code{\link[=text_line_dataset]{text_line_dataset()}} and \code{\link[=dataset_decode_delim]{dataset_decode_delim()}} functions.

The \code{\link[=csv_dataset]{csv_dataset()}} and \code{\link[=tsv_dataset]{tsv_dataset()}} are wrappers that parse comma
and tab separated text files respectively.
}
