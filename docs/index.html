<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>R interface to 'TensorFlow' Datasets API • tfdatasets</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="jquery.sticky-kit.min.js"></script><script src="pkgdown.js"></script><link href="extra.css" rel="stylesheet">
<script src="extra.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">tfdatasets</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/tfdatasets">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    

    
    
<div class="contents">
<div id="tfdatasets-r-interface-to-tensorflow-datasets-api" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#tfdatasets-r-interface-to-tensorflow-datasets-api" class="anchor"></a>tfdatasets: R interface to TensorFlow Datasets API</h1></div>
<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p>The TensorFlow Datasets API provides various facilities for creating scalable input pipelines for TensorFlow models, including:</p>
<ul>
<li><p>Reading data from a variety of formats including CSV files and <a href="https://www.tensorflow.org/api_guides/python/python_io#tfrecords_format_details">TFRecords files</a> (the standard binary format for TensorFlow training data).</p></li>
<li><p>Transforming datasets in a variety of ways including mapping arbitrary functions against them.</p></li>
<li><p>Shuffling, batching, and repeating datasets over a number of epochs.</p></li>
<li><p>Streaming interface to data for reading arbitrarily large datasets.</p></li>
<li><p>Reading and transforming data are TensorFlow graph operations, so are executed in C++ and in parallel with model training.</p></li>
</ul>
<p>The R interface to TensorFlow datasets provides access to the Dataset API, including high-level convenience functions for easy integration with the <a href="https://tensorflow.rstudio.com/keras">keras</a> and <a href="https://tensorflow.rstudio.com/tfestimators">tfestimators</a> R packages.</p>
</div>
<div id="installation" class="section level2">
<h2 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h2>
<p>To use <strong>tfdatasets</strong> you need to install both the R package as well as <a href="https://rstudio.github.io/tensorflow/">TensorFlow</a> itself.</p>
<p>First, install the tfdatasets R package as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"rstudio/tfdatasets"</span>)</code></pre></div>
<p>Then, use the <code><a href="http://www.rdocumentation.org/packages/tensorflow/topics/install_tensorflow">install_tensorflow()</a></code> function to install TensorFlow:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tfdtasets)
<span class="kw"><a href="http://www.rdocumentation.org/packages/tensorflow/topics/install_tensorflow">install_tensorflow</a></span>()</code></pre></div>
<div class="alert alert-warning" role="alert">
<p><strong>IMPORTANT NOTE</strong>: The <strong>tfdatasets</strong> package requires the very latest version of TensorFlow (v1.4) so you should be sure to update to v1.4 before using the package (you can do this with the install_tensorflow() function shown above).</p>
</div>
</div>
<div id="creating-a-dataset" class="section level2">
<h2 class="hasAnchor">
<a href="#creating-a-dataset" class="anchor"></a>Creating a Dataset</h2>
<p>To create a dataset, use one of the <a href="reference/index.html#section-creating-datasets">dataset creation</a> functions. Dataset can be created from delimted text files, <a href="https://www.tensorflow.org/api_guides/python/python_io#tfrecords_format_details">TFRecords files</a>, as well as from in-memory data.</p>
<div id="text-files" class="section level3">
<h3 class="hasAnchor">
<a href="#text-files" class="anchor"></a>Text Files</h3>
<p>For example, to create a dataset from a text file, first create a specification for how records will be decoded from the file, then call <code><a href="reference/text_line_dataset.html">text_line_dataset()</a></code> with the file to be read and the specification:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tfdatasets)

<span class="co"># create specification for parsing records from an example file</span>
iris_spec &lt;-<span class="st"> </span><span class="kw"><a href="reference/delim_record_spec.html">csv_record_spec</a></span>(<span class="st">"iris.csv"</span>)

<span class="co"># read the datset</span>
dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"iris.csv"</span>, <span class="dt">record_spec =</span> iris_spec)

<span class="co"># take a glimpse at the dataset</span>
<span class="kw">str</span>(dataset)</code></pre></div>
<pre><code>TensorFlow Dataset
Petal.Length : &lt;tf.float32&gt; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1...
Sepal.Length : &lt;tf.float32&gt; 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5...
Petal.Width  : &lt;tf.float32&gt; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0...
Sepal.Width  : &lt;tf.float32&gt; 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3 3 4 4.4 3.9 3...
Species      : &lt;tf.int32&gt;   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ..</code></pre>
<p>In the example above, the <code><a href="reference/delim_record_spec.html">csv_record_spec()</a></code> function is passed an example file which is used to automatically detect column names and types (done by reading up to the first 1,000 lines of the file). You can also provide explicit column names and/or data types using the <code>names</code> and <code>types</code> parameters (note that in this case we don’t pass an example file):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># provide colum names and types explicitly</span>
iris_spec &lt;-<span class="st"> </span><span class="kw"><a href="reference/delim_record_spec.html">csv_record_spec</a></span>(
  <span class="dt">names =</span> <span class="kw">c</span>(<span class="st">"SepalLength"</span>, <span class="st">"SepalWidth"</span>, <span class="st">"PetalLength"</span>, <span class="st">"PetalWidth"</span>, <span class="st">"Species"</span>),
  <span class="dt">types =</span> <span class="kw">c</span>(<span class="st">"double"</span>, <span class="st">"double"</span>, <span class="st">"double"</span>, <span class="st">"double"</span>, <span class="st">"integer"</span>), 
  <span class="dt">skip =</span> <span class="dv">1</span>
)

<span class="co"># read the datset</span>
dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"iris.csv"</span>, <span class="dt">record_spec =</span> iris_spec)</code></pre></div>
<p>Note that we’ve also specified <code>skip = 1</code> to indicate that the first row of the CSV that contains column names should be skipped.</p>
<p>Supported column types are integer, double, and character. You can also provide <code>types</code> in a more compact form using single-letter abbreviations (e.g. <code>types = "dddi"</code>). For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mtcars_spec &lt;-<span class="st"> </span><span class="kw"><a href="reference/delim_record_spec.html">csv_record_spec</a></span>(<span class="st">"mtcars.csv"</span>, <span class="dt">types =</span> <span class="st">"dididddiiii"</span>)</code></pre></div>
<div id="parallel-decoding" class="section level4">
<h4 class="hasAnchor">
<a href="#parallel-decoding" class="anchor"></a>Parallel Decoding</h4>
<p>Decoding lines of text into a record can be computationally expensive. You can parallelize these computations using the <code>parallel_records</code> parameter. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"iris.csv"</span>, <span class="dt">record_spec =</span> iris_spec, <span class="dt">parallel_records =</span> <span class="dv">4</span>)</code></pre></div>
<p>You can also parallelize the reading of data from storage by requesting that a buffer of records be prefected. You do this with the <code><a href="reference/dataset_prefetch.html">dataset_prefetch()</a></code> function. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"iris.csv"</span>, <span class="dt">record_spec =</span> iris_spec, <span class="dt">parallel_records =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prefetch.html">dataset_prefetch</a></span>(<span class="dv">1000</span>)</code></pre></div>
<p>If you have multiple input files, you can also parallelize reading of these files both across multiple machines (sharding) and/or on multiple threads per-machine (parallel reads with interleaving). See the section on <a href="#reading-multiple-files">Reading Multiple Files</a> below for additional details.</p>
</div>
</div>
<div id="tfrecords-files" class="section level3">
<h3 class="hasAnchor">
<a href="#tfrecords-files" class="anchor"></a>TFRecords Files</h3>
<p>You can read datasets from <a href="https://www.tensorflow.org/api_guides/python/python_io#tfrecords_format_details">TFRecords files</a> using the <code><a href="reference/tfrecord_dataset.html">tfrecord_dataset()</a></code> function.</p>
<p>In many cases you’ll want to map the records in the dataset into a set of named columns. You can do this using the <code><a href="reference/dataset_map.html">dataset_map()</a></code> function along with the <code>tf$parse_single_example()</code> function. for example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Creates a dataset that reads all of the examples from two files, and extracts</span>
<span class="co"># the image and label features.</span>
filenames &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"/var/data/file1.tfrecord"</span>, <span class="st">"/var/data/file2.tfrecord"</span>)
dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/tfrecord_dataset.html">tfrecord_dataset</a></span>(filenames) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_map.html">dataset_map</a></span>(<span class="cf">function</span>(example_proto) {
    features &lt;-<span class="st"> </span><span class="kw">list</span>(
      <span class="dt">image =</span> tf<span class="op">$</span><span class="kw">FixedLenFeature</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/tensorflow/topics/shape">shape</a></span>(), tf<span class="op">$</span>string, <span class="dt">default_value =</span> <span class="st">""</span>),
      <span class="dt">label =</span> tf<span class="op">$</span><span class="kw">FixedLenFeature</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/tensorflow/topics/shape">shape</a></span>(), tf<span class="op">$</span>int32, <span class="dt">default_value =</span> 0L)
    )
    tf<span class="op">$</span><span class="kw">parse_single_example</span>(example_proto, features)
  })</code></pre></div>
</div>
</div>
<div id="transformations" class="section level2">
<h2 class="hasAnchor">
<a href="#transformations" class="anchor"></a>Transformations</h2>
<div id="mapping" class="section level3">
<h3 class="hasAnchor">
<a href="#mapping" class="anchor"></a>Mapping</h3>
<p>You can map arbitrary transformation functions onto dataset records using the <code><a href="reference/dataset_map.html">dataset_map()</a></code> function. For example, to transform the “Species” column into a one-hot encoded vector you would do this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span>dataset <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_map.html">dataset_map</a></span>(<span class="cf">function</span>(record) {
    record<span class="op">$</span>Species &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">one_hot</span>(record<span class="op">$</span>Species, 3L)
    record
  })</code></pre></div>
<p>Note that while <code><a href="reference/dataset_map.html">dataset_map()</a></code> is defined using an R function, there are some special constraints on this function which allow it to execute <em>not within R</em> but rather within the TensorFlow graph.</p>
<p>For a dataset created with the <code>csv_dataset()</code> function, the passed record will be named list of tensors (one for each column of the dataset). The return value should be another set of tensors which were created from TensorFlow functions (e.g. <code>tf$one_hot</code> as illustrated above). This function will be converted to a TensorFlow graph operation that performs the transformation within native code.</p>
<div id="parallel-mapping" class="section level4">
<h4 class="hasAnchor">
<a href="#parallel-mapping" class="anchor"></a>Parallel Mapping</h4>
<p>If these transformations are computationally expensive they can be executed on multiple threads using the <code>num_parallel_calls</code> parameter. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span>dataset <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_map.html">dataset_map</a></span>(<span class="dt">num_parallel_calls =</span> <span class="dv">4</span>, <span class="cf">function</span>(record) {
    record<span class="op">$</span>Species &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">one_hot</span>(record<span class="op">$</span>Species, 3L)
    record
  })</code></pre></div>
<p>You can control the maximum number of processed elements that will be buffered when processing in parallel using the <code><a href="reference/dataset_prefetch.html">dataset_prefetch()</a></code> transformation. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span>dataset <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_map.html">dataset_map</a></span>(<span class="dt">num_parallel_calls =</span> <span class="dv">4</span>, <span class="cf">function</span>(record) {
    record<span class="op">$</span>Species &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">one_hot</span>(record<span class="op">$</span>Species, 3L)
    record
  }) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">datset_prefetch</span>(<span class="dv">100</span>)</code></pre></div>
</div>
</div>
<div id="filtering" class="section level3">
<h3 class="hasAnchor">
<a href="#filtering" class="anchor"></a>Filtering</h3>
<p>You can filter the elements of a dataset using the <code><a href="reference/dataset_filter.html">dataset_filter()</a></code> function, which takes a <code>predicate</code> function that returns a boolean tensor for records that should be included. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw">csv_dataset</span>(<span class="st">"mtcars.csv"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_filter.html">dataset_filter</a></span>(<span class="cf">function</span>(record) {
    record<span class="op">$</span>mpg <span class="op">&gt;=</span><span class="st"> </span><span class="dv">20</span>
})

dataset &lt;-<span class="st"> </span><span class="kw">csv_dataset</span>(<span class="st">"mtcars.csv"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_filter.html">dataset_filter</a></span>(<span class="cf">function</span>(record) {
    record<span class="op">$</span>mpg <span class="op">&gt;=</span><span class="st"> </span><span class="dv">20</span> <span class="op">&amp;</span><span class="st"> </span>record<span class="op">$</span>cyl <span class="op">&gt;=</span><span class="st"> </span>6L
  })</code></pre></div>
<p>Note that the functions used inside the predicate must be tensor operations (e.g. <code>tf$not_equal</code>, <code>tf$less</code>, etc.). R generic methods for relational operators (e.g. &lt;, &gt;, &lt;=, etc.) and logical operators (e.g. !, &amp;, |, etc.) are provided so you can use shorthand syntax for most common comparisions (as illustrated above).</p>
</div>
<div id="features-and-response" class="section level3">
<h3 class="hasAnchor">
<a href="#features-and-response" class="anchor"></a>Features and Response</h3>
<p>A common transformation is taking a column oriented dataset (e.g. one created by <code>csv_dataset()</code> or <code><a href="reference/tfrecord_dataset.html">tfrecord_dataset()</a></code>) and transforming it into a two-element list with features (“x”) and response (“y”). You can use the <code><a href="reference/dataset_prepare.html">dataset_prepare()</a></code> function to do this type of transformation. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mtcars_dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"mtcars.csv"</span>, <span class="dt">record_spec =</span> mtcars_spec) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prepare.html">dataset_prepare</a></span>(<span class="dt">x =</span> <span class="kw">c</span>(mpg, disp), <span class="dt">y =</span> cyl)

iris_dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"iris.csv"</span>, <span class="dt">record_spec =</span> iris_spec) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prepare.html">dataset_prepare</a></span>(<span class="dt">x =</span> <span class="op">-</span>Species, <span class="dt">y =</span> Species)</code></pre></div>
<p>The <code><a href="reference/dataset_prepare.html">dataset_prepare()</a></code> function also accepts standard R formula syntax for defining features and response:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mtcars_dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"mtcars.csv"</span>, <span class="dt">record_spec =</span> mtcars_spec) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prepare.html">dataset_prepare</a></span>(cyl <span class="op">~</span><span class="st"> </span>mpg <span class="op">+</span><span class="st"> </span>disp)</code></pre></div>
</div>
<div id="shuffling-and-batching" class="section level3">
<h3 class="hasAnchor">
<a href="#shuffling-and-batching" class="anchor"></a>Shuffling and Batching</h3>
<p>There are several functions which control how batches are drawn from the dataset. For example, the following specifies that data will be drawn in batches of 128 from a shuffled window of 1000 records, and that the dataset will be repeated for 10 epochs:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span>dataset <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_shuffle.html">dataset_shuffle</a></span>(<span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">128</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_repeat.html">dataset_repeat</a></span>(<span class="dv">10</span>)</code></pre></div>
</div>
<div id="complete-example" class="section level3">
<h3 class="hasAnchor">
<a href="#complete-example" class="anchor"></a>Complete Example</h3>
<p>Here’s a complete example of using the various dataset transformation functions together. We’ll read the <code>mtcars</code> dataset from a CSV, filter it on some threshold values, map it into <code>x</code> and <code>y</code> components for modeling, and specify desired shuffling and batch iteration behavior:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"mtcars.csv"</span>, <span class="dt">record_spec =</span> mtcars_spec) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prefetch.html">dataset_prefetch</a></span>(<span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_filter.html">dataset_filter</a></span>(<span class="cf">function</span>(record) {
    record<span class="op">$</span>mpg <span class="op">&gt;=</span><span class="st"> </span><span class="dv">20</span> <span class="op">&amp;</span><span class="st"> </span>record<span class="op">$</span>cyl <span class="op">&gt;=</span><span class="st"> </span>6L
  }) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prepare.html">dataset_prepare</a></span>(cyl <span class="op">~</span><span class="st"> </span>mpg <span class="op">+</span><span class="st"> </span>disp) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_shuffle.html">dataset_shuffle</a></span>(<span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">128</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_repeat.html">dataset_repeat</a></span>(<span class="dv">10</span>)</code></pre></div>
</div>
</div>
<div id="reading-datasets" class="section level2">
<h2 class="hasAnchor">
<a href="#reading-datasets" class="anchor"></a>Reading Datasets</h2>
<p>You read batches of data from a dataset by using tensors that yield the next batch. You can obtain this tensor from a dataset via the <code><a href="reference/next_batch.html">next_batch()</a></code> function. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"mtcars.csv"</span>, <span class="dt">record_spec =</span> mtcars_spec) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prepare.html">dataset_prepare</a></span>(cyl <span class="op">~</span><span class="st"> </span>mpg <span class="op">+</span><span class="st"> </span>disp) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_shuffle.html">dataset_shuffle</a></span>(<span class="dv">20</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">5</span>)
batch &lt;-<span class="st"> </span><span class="kw"><a href="reference/next_batch.html">next_batch</a></span>(dataset)
batch</code></pre></div>
<pre><code>$x
Tensor("IteratorGetNext_13:0", shape=(?, 2), dtype=float32)

$y
Tensor("IteratorGetNext_13:1", shape=(?,), dtype=int32)</code></pre>
<p>As you can see <code>batch</code> isn’t the data itself but rather a tensor that will yield the next batch of data when it is evaluated:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sess &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Session</span>()
sess<span class="op">$</span><span class="kw">run</span>(batch)</code></pre></div>
<pre><code>$x
     [,1] [,2]
[1,] 21.0  160
[2,] 21.0  160
[3,] 22.8  108
[4,] 21.4  258
[5,] 18.7  360

$y
[1] 6 6 4 6 8</code></pre>
</div>
<div id="dataset-iteration" class="section level2">
<h2 class="hasAnchor">
<a href="#dataset-iteration" class="anchor"></a>Dataset Iteration</h2>
<p>If you are iterating over an entire dataset by evaluating the <code><a href="reference/next_batch.html">next_batch()</a></code> tensor you will need to determine at what point to stop iteration. There are a couple of possible approaches to controlling/detecting when iteration should end.</p>
<p>One approach is to create a dataset that yields batches infinitely (traversing the dataset multiple times with different batches randomly drawn). In this case you’d use another mechanism like a global step counter or detecting a learning plateau:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tfdatasets)
dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"mtcars.csv"</span>, <span class="dt">record_spec =</span> mtcars_spec) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prepare.html">dataset_prepare</a></span>(<span class="dt">x =</span> <span class="kw">c</span>(mpg, disp), <span class="dt">y =</span> cyl) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_shuffle.html">dataset_shuffle</a></span>(<span class="dv">5000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">128</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_repeat.html">dataset_repeat</a></span>() <span class="co"># repeat infinitely</span>

batch &lt;-<span class="st"> </span><span class="kw"><a href="reference/next_batch.html">next_batch</a></span>(dataset)

steps &lt;-<span class="st"> </span><span class="dv">200</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>steps) {
  <span class="co"># use batch$x and batch$y tensors</span>
}</code></pre></div>
<p>The call to <code><a href="reference/dataset_repeat.html">dataset_repeat()</a></code> with no <code>count</code> parameter requests that the dataset be traversed infinitely.</p>
<p>Another approach is to detect when all batches have been yielded from the dataset. When the tensor reaches the end of iteration a runtime error will occur. You can catch and ignore the error when it occurs by wrapping your iteration code in the <code><a href="reference/with_dataset.html">with_dataset()</a></code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tfdatasets)
dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"mtcars.csv"</span>, <span class="dt">record_spec =</span> mtcars_spec) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prepare.html">dataset_prepare</a></span>(<span class="dt">x =</span> <span class="kw">c</span>(mpg, disp), <span class="dt">y =</span> cyl) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">128</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_repeat.html">dataset_repeat</a></span>(<span class="dv">10</span>)
  
batch &lt;-<span class="st"> </span><span class="kw"><a href="reference/next_batch.html">next_batch</a></span>(dataset)

<span class="kw"><a href="reference/with_dataset.html">with_dataset</a></span>({
  <span class="cf">while</span>(<span class="ot">TRUE</span>) {
    <span class="co"># use batch$x and batch$y tensors</span>
  }
})</code></pre></div>
</div>
<div id="using-with-tfestimators" class="section level2">
<h2 class="hasAnchor">
<a href="#using-with-tfestimators" class="anchor"></a>Using with tfestimators</h2>
<p>Models created with <strong>tfestimators</strong> use an input function to consume data for training, evaluation, and prediction. For example, here is an example of using an input function to feed data from an in-memory R data frame to an estimators model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">train</span>(
  <span class="kw"><a href="reference/input_fn.html">input_fn</a></span>(mtcars, <span class="dt">features =</span> <span class="kw">c</span>(mpg, disp), <span class="dt">response =</span> cyl,
           <span class="dt">batch_size =</span> <span class="dv">128</span>, <span class="dt">epochs =</span> <span class="dv">3</span>)
)</code></pre></div>
<p>If you are using <strong>tfdatasets</strong> with the <strong>tfestimators</strong> package, you can create an estimators input function directly from a dataset as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"mtcars.csv"</span>, <span class="dt">record_spec =</span> mtcars_spec) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">128</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_repeat.html">dataset_repeat</a></span>(<span class="dv">3</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">train</span>(
  <span class="kw"><a href="reference/input_fn.html">input_fn</a></span>(dataset, <span class="dt">features =</span> <span class="kw">c</span>(mpg, disp), <span class="dt">response =</span> cyl)
)</code></pre></div>
<p>Note that we don’t use the <code><a href="reference/dataset_prepare.html">dataset_prepare()</a></code> or <code><a href="reference/next_batch.html">next_batch()</a></code> functions in this example. Rather, these functions are used under the hood to provide the <code>input_fn</code> interface expected by tfestimators models.</p>
<p>As with <code><a href="reference/dataset_prepare.html">dataset_prepare()</a></code>, you can alternatively use an R formula to specify features and response:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">train</span>(
  <span class="kw"><a href="reference/input_fn.html">input_fn</a></span>(dataset, cyl <span class="op">~</span><span class="st"> </span>mpg <span class="op">+</span><span class="st"> </span>disp)
)</code></pre></div>
</div>
<div id="using-with-keras" class="section level2">
<h2 class="hasAnchor">
<a href="#using-with-keras" class="anchor"></a>Using with Keras</h2>
<p>Keras models are often trained by passing in-memory arrays directly to the <code>fit</code> function. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(
  x_train, y_train, 
  <span class="dt">epochs =</span> <span class="dv">30</span>, 
  <span class="dt">batch_size =</span> <span class="dv">128</span>
)</code></pre></div>
<p>However, this requires loading data into an R data frame or matrix before calling fit. You can use the <code><a href="http://www.rdocumentation.org/packages/keras/topics/train_on_batch">train_on_batch()</a></code> function to stream data one batch at a time, however the reading and processing of the input data is still being done serially and outside of native code.</p>
<p>Alternatively, Keras enables you to wire input and output tensors directly into the model definition, which are then evaluated for each training step. You can combine this capability with <code><a href="reference/dataset_prepare.html">dataset_prepare()</a></code> and <code><a href="reference/next_batch.html">next_batch()</a></code> to efficiently stream data into Keras training operations. Here is a complete example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(keras)
<span class="kw">library</span>(tfdatasets)
  
<span class="co"># create dataset that yields batches infinitely</span>
dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/text_line_dataset.html">text_line_dataset</a></span>(<span class="st">"iris.csv"</span>, <span class="dt">record_spec =</span> iris_spec) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_map.html">dataset_map</a></span>(<span class="cf">function</span>(record) {
    record<span class="op">$</span>Species &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">one_hot</span>(record<span class="op">$</span>Species, <span class="dt">depth =</span> 3L)
    record
  }) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prepare.html">dataset_prepare</a></span>(<span class="dt">x =</span> <span class="op">-</span>Species, <span class="dt">y =</span> Species) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_shuffle.html">dataset_shuffle</a></span>(<span class="dv">1000</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">128</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_repeat.html">dataset_repeat</a></span>() 

<span class="co"># stream batches from dataset</span>
batch &lt;-<span class="st"> </span><span class="kw"><a href="reference/next_batch.html">next_batch</a></span>(dataset)

<span class="co"># create model</span>
input &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/layer_input">layer_input</a></span>(<span class="dt">tensor =</span> batch<span class="op">$</span>x, <span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">4</span>))
predictions &lt;-<span class="st"> </span>input <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/layer_dense">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/layer_dense">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">20</span>, <span class="dt">activation =</span> <span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/layer_dense">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">3</span>, <span class="dt">activation =</span> <span class="st">"softmax"</span>)
model &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/keras_model">keras_model</a></span>(input, predictions)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/compile">compile</a></span>(
  <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>,
  <span class="dt">optimizer =</span> <span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/optimizer_rmsprop">optimizer_rmsprop</a></span>(),
  <span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">'accuracy'</span>),
  <span class="dt">target_tensors =</span> batch<span class="op">$</span>y
)

<span class="co"># fit the model</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/fit">fit</a></span>(
  <span class="dt">steps_per_epoch =</span> <span class="dv">30</span>,
  <span class="dt">epochs =</span> <span class="dv">5</span>
)</code></pre></div>
<p>Note that we don’t pass <code>x_train</code> or <code>y_train</code> to <code><a href="http://www.rdocumentation.org/packages/keras/topics/fit">fit()</a></code>, rather the feature data (<code>batch$x</code>) is provided as the <code>tensor</code> argument to <code><a href="http://www.rdocumentation.org/packages/keras/topics/layer_input">layer_input()</a></code> and the response data (<code>batch$y</code>) is provided as the <code>target_tensors</code> argument to <code><a href="http://www.rdocumentation.org/packages/keras/topics/compile">compile()</a></code>. The training data is directly wired into the TensorFlow graph built for the model.</p>
<p>Note also that rather than calling the Keras <code><a href="http://www.rdocumentation.org/packages/keras/topics/to_categorical">to_categorical()</a></code> function to one-hot encode the “Species” field, we do this instead in a <code><a href="reference/dataset_map.html">dataset_map()</a></code> operation that calls the <code>tf$one_hot()</code> function.</p>
</div>
<div id="reading-multiple-files" class="section level2">
<h2 class="hasAnchor">
<a href="#reading-multiple-files" class="anchor"></a>Reading Multiple Files</h2>
<p>If you have multiple input files you can process them in parallel both across machines (sharding) and/or on multiple threads per-machine (parallel reads with interleaving). The <code><a href="reference/read_files.html">read_files()</a></code> function provides a high-level interface to parallel file reading.</p>
<p>The <code><a href="reference/read_files.html">read_files()</a></code> function takes a set of files and a read function along with various options to orchestrate parallel reading. For example, the following function reads all CSV files in a directory using the <code><a href="reference/text_line_dataset.html">text_line_dataset()</a></code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/read_files.html">read_files</a></span>(<span class="st">"data/*.csv"</span>, text_line_dataset, <span class="dt">record_spec =</span> mtcars_spec,
                      <span class="dt">parallel_files =</span> <span class="dv">4</span>, <span class="dt">parallel_interleave =</span> <span class="dv">16</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prefetch.html">dataset_prefetch</a></span>(<span class="dv">5000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_shuffle.html">dataset_shuffle</a></span>(<span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">128</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_repeat.html">dataset_repeat</a></span>(<span class="dv">3</span>)</code></pre></div>
<p>The <code>parallel_files</code> argument requests that 4 files be processed in parallel and the <code>parallel_interleave</code> argument requests that blocks of 16 consecutive records from each file be interleaved in the resulting dataset.</p>
<p>Note that because we are processing files in parallel we <em>do not</em> pass the <code>parallel_records</code> argument to <code><a href="reference/text_line_dataset.html">text_line_dataset()</a></code>, since we are already parallelizing at the file level.</p>
<div id="multiple-machines" class="section level3">
<h3 class="hasAnchor">
<a href="#multiple-machines" class="anchor"></a>Multiple Machines</h3>
<p>If you are training on multiple machines and the training supervisor passes a shard index to your training script, you can also parallelizing reading by sharding the file list. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># command line flags for training script (shard info is passed by training </span>
<span class="co"># supervisor that executes the script)</span>
FLAGS &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/reexports">flags</a></span>(
  <span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/reexports">flag_integer</a></span>(<span class="st">"num_shards"</span>, <span class="dv">1</span>),
  <span class="kw">flag_integeR</span>(<span class="st">"shard_index"</span>, <span class="dv">1</span>)
)

<span class="co"># forward shard info to read_files</span>
dataset &lt;-<span class="st"> </span><span class="kw"><a href="reference/read_files.html">read_files</a></span>(<span class="st">"data/*.csv"</span>, text_line_dataset, <span class="dt">record_spec =</span> mtcars_spec,
                      <span class="dt">parallel_files =</span> <span class="dv">4</span>, <span class="dt">parallel_interleave =</span> <span class="dv">16</span>,
                      <span class="dt">num_shards =</span> FLAGS<span class="op">$</span>num_shards, <span class="dt">shard_index =</span> FLAGS<span class="op">$</span>shard_index) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_prefetch.html">dataset_prefetch</a></span>(<span class="dv">5000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_shuffle.html">dataset_shuffle</a></span>(<span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_batch.html">dataset_batch</a></span>(<span class="dv">128</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="reference/dataset_repeat.html">dataset_repeat</a></span>(<span class="dv">3</span>)</code></pre></div>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2 class="hasAnchor">
<a href="#sidebar" class="anchor"></a>Links</h2>
<ul class="list-unstyled">
<li>Browse source code at <br><a href="https://github.com/rstudio/tfdatasets">https://​github.com/​rstudio/​tfdatasets</a>
</li>
<li>Report a bug at <br><a href="https://github.com/rstudio/tfdatasets/issues">https://​github.com/​rstudio/​tfdatasets/​issues</a>
</li>
</ul>
<h2>License</h2>
<p>Apache License 2.0</p>
<h2>Developers</h2>
<ul class="list-unstyled">
<li>JJ Allaire <br><small class="roles"> Author, maintainer </small> </li>
<li>Yuan Tang <br><small class="roles"> Author </small> </li>
<li>Kevin Ushey <br><small class="roles"> Author </small> </li>
<li>
<a href="https://www.rstudio.com"><img src="http://tidyverse.org/rstudio-logo.svg" height="24"></a> <br><small class="roles"> Copyright holder, funder </small> </li>
<li><a href="authors.html">All authors...</a></li>
</ul>
</div>

</div>


      <footer><div class="copyright">
  <p>Developed by JJ Allaire, Yuan Tang, Kevin Ushey, <a href="https://www.rstudio.com"><img src="http://tidyverse.org/rstudio-logo.svg" height="24"></a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
